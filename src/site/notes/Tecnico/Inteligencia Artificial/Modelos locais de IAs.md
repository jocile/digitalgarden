---
{"dg-publish":true,"permalink":"/tecnico/inteligencia-artificial/modelos-locais-de-i-as/","title":"Modelos locais de IAs","metatags":{"description":"A principal vantagem em usar modelos locais √© que al√©m de n√£o necessitar de internet, n√£o ter os tradicionais limites pagos de uso, e ainda poder treinar e testar diferentes modelos de IAs."},"tags":["Inteligencia-artificial","Modelos","LLM","Ollama"],"noteIcon":"1","updated":"2025-01-20T20:42:31.677-03:00"}
---


## Modelos locais de IAs

A principal vantagem em usar modelos locais √© que al√©m de n√£o necessitar de internet, n√£o ter os tradicionais limites pagos de uso, e ainda poder treinar e testar diferentes modelos de IAs.

### O que √© um modelo de linguagem

Um modelo de linguagem √© um sistema de intelig√™ncia artificial que aprende a gerar ou processar texto com base em exemplos de treinamento. Ele √© treinado em grandes quantidades de texto para aprender a prever a pr√≥xima palavra ou frase com base no contexto anterior. 

Os modelos de linguagem podem ser usados para diversas tarefas, como:

- Tradu√ß√£o autom√°tica
- Gera√ß√£o de texto
- Resumo autom√°tico 
- Resposta a perguntas
- Gerar e explicar c√≥digos de programa√ß√£o.

Os modelos de linguagem mais recentes, como o GPT-4 da OpenAI, s√£o baseados em redes neurais profundas e apresentam um desempenho impressionante em v√°rias tarefas de processamento de linguagem.

Embora o termo n√£o tenha uma defini√ß√£o formal, ele geralmente se refere a modelos de aprendizado profundo que possuem uma contagem de par√¢metros da ordem de bilh√µes ou mais. Esses modelos de prop√≥sito geral se destacam em uma ampla gama de tarefas, em vez de serem treinados para uma tarefa espec√≠fica.

Al√©m de prever a pr√≥xima palavra, modelos de linguagem neural com treinamento e contagem de par√¢metros suficientes s√£o capazes de capturar grande parte da sintaxe e sem√¢ntica da linguagem humana. Eles tamb√©m demonstram consider√°vel conhecimento geral sobre o mundo e s√£o capazes de "memorizar" uma grande quantidade de fatos durante o treinamento.

Em contraste, a defini√ß√£o mais b√°sica de um modelo de linguagem refere-se ao conceito de atribuir probabilidades a sequ√™ncias de palavras, com base na an√°lise de corpora de texto. Esses modelos podem variar de complexidade, desde modelos simples de n-gram at√© modelos de rede neural mais sofisticados.

### Usando os modelos locais de linguagem

Para usar os modelos de linguagem precisamos de uma interface de comunica√ß√£o, foi por isso que o ChatGPT popularizou o uso dos modelos, por facilitar a intera√ß√£o como um chat.

#### Interfaces para usar os modelos locais

1. Primeiramente instale o Ollama e com ele execute os modelos locais:
 - [Ollama](https://ollama.com/): √© uma plataforma que fornece acesso local a uma variedade de modelos de linguagem, incluindo o Llama 3, Gemma 2, CodeLlama e outros. Ela oferece uma interface por API para interagir com esses modelos de maneira f√°cil e acess√≠vel.

1. Em seguida instale uma interface para gerenciar os prompts e as notas geradas, a mais simples √© um plugin no Chrome, e a mais moderna √© a Msty:
 - [ollama-ui: Simple HTML UI para o Ollama](https://github.com/rtcfirefly/ollama-ui) - √â uma interface Web para o Ollama que interage atrav√©s de um plugin do Chrome.
 - [Open WebUI](https://docs.openwebui.com/): √© uma interface web intuitiva e de c√≥digo aberto que permite interagir com a API do Ollama para usar diversos modelos de linguagem, incluindo o Mistral, Llama 3 e outros. Ela fornece recursos avan√ßados como gera√ß√£o de c√≥digo, an√°lise de texto e at√© mesmo integra√ß√£o com APIs externas.
 - Extens√µes: permitem acessar os modelos em editores de c√≥digo, como o VsCode, de forma a interagir com a API do Ollama e auxiliar na programa√ß√£o, atuando de forma local de maneira similar ao Copilot do Windows. Exemplos de extens√µes s√£o o [Cody](https://marketplace.visualstudio.com/items?itemName=sourcegraph.cody-ai) e o [‚ö°Ô∏è Continue](https://docs.continue.dev/quickstart).
 - [msty.app](https://msty.app/) - Interface para acessar o Ollama de f√°cil instala√ß√£o, com ela monte sua base de conhecimento a partir de documentos e pastas, com gerenciamento de prompts, uso de modelos em paralelo, instru√ß√£o personalizada de modelos, modo offline, auto update, simplesmente a melhor!

#### Como usar localmente os modelos

- **Ollama**: Na plataforma [Ollama](Ollama.md), voc√™ pode selecionar o modelo de linguagem desejado (como Llama 3, Gemma 2 ou CodeLlama) e ent√£o interagir com ele atrav√©s do terminal do linux ou Prompt do Windows. Voc√™ pode enviar comandos, perguntas, solicitar tarefas de codifica√ß√£o, gerar texto e muito mais. A interface tamb√©m fornece op√ß√µes para ajustar par√¢metros como o tamanho da sa√≠da.
- Em [github.com/ollama/ollama](https://github.com/ollama/ollama) podemos fazer o download e instalar conforme seu sistema operacional, e usar um modelo digitando no prompt:

```powershell
ollama run llama3
```

- Com este comando, o Ollama baixa e executa o modelo llama3, ou outros modelos, veja a lista em [library](https://ollama.com/library), isso simplifica o acesso e a intera√ß√£o com esses poderosos modelos de linguagem, permitindo que desenvolvedores, pesquisadores e usu√°rios em geral possam aproveitar seus recursos de maneira intuitiva e acess√≠vel.
- Os principais comandos do Ollama s√£o:
	- `ollama pull llama3` - atualiza o modelo;
	- `ollama rm llama3` - remove o modelo;
	- `ollama show llama3` - mostra informa√ß√µes do modelo;
	- `ollama list` - lista os modelos instalados.
- Para uma interface com mais recursos use o Msty, com gerenciamento de seus documentos como uma base de pesquisa, gerenciamento de prompts, personaliza√ß√£o de modelos, etc.

### Principais diferen√ßas entre os modelos de linguagem

#### Llama 3 vs Gemma 2

- O Llama 3 √© um modelo de linguagem de grande porte (at√© 65 bilh√µes de par√¢metros) desenvolvido pela Anthropic, enquanto o Gemma 2 √© um modelo menor (9B e 27B) desenvolvido pela Google.
- O Llama 3 √© focado em tarefas gerais de linguagem, enquanto o Gemma 2 √© mais voltado para aplica√ß√µes de c√≥digo e programa√ß√£o.
- Apesar de menor, o Gemma 2 tem um desempenho compar√°vel ao Llama 3 em algumas tarefas de codifica√ß√£o.

#### CodeLlama vs StarCoder

- O CodeLlama √© um modelo de linguagem especializado em tarefas de programa√ß√£o, desenvolvido pela Anthropic.
- O StarCoder √© um modelo similar, desenvolvido pelo projeto BigCode, que tamb√©m se concentra em gera√ß√£o de c√≥digo em diversas linguagens de programa√ß√£o.
- O CodeLlama 34B supera o desempenho de outros modelos open-source em benchmarks de codifica√ß√£o, como HumanEval e MBPP.
- Vers√µes fine-tuned do CodeLlama, como o Phind-CodeLlama, alcan√ßam resultados ainda melhores nesses benchmarks.

#### Mistral vs Claude

- O Mistral √© um modelo open-source de 7 bilh√µes de par√¢metros, desenvolvido com t√©cnicas como Grouped Query Attention e Sliding Window Attention para melhorar a efici√™ncia.
- O Claude √© um modelo propriet√°rio da Anthropic, com foco em tarefas gerais de linguagem, n√£o sendo especializado em codifica√ß√£o como o Mistral.
- Apesar de menor, o Mistral tem um desempenho compar√°vel ao CodeLlama 7B em tarefas de programa√ß√£o, mantendo bom desempenho em outras tarefas de linguagem.

Em resumo, os modelos diferem principalmente no tamanho, foco (codifica√ß√£o vs. linguagem geral) e desempenho em benchmarks espec√≠ficos de programa√ß√£o. Modelos como CodeLlama, StarCoder e vers√µes fine-tuned se destacam em tarefas de codifica√ß√£o, enquanto modelos como Llama 3, Gemma 2 e Mistral t√™m um escopo mais amplo.

### Tabela comparativa

Aqui est√° uma tabela comparando as principais diferen√ßas entre os modelos de linguagem mencionados:

| Modelo | Tamanho | Foco | Destaques |
|--------|---------|------|-----------|
| Llama 3 | At√© 65B par√¢metros | Tarefas gerais de linguagem | Modelo de grande porte da Anthropic |
| Gemma 2 | 9B e 27B par√¢metros | Aplica√ß√µes de c√≥digo e programa√ß√£o | Bom desempenho em tarefas de codifica√ß√£o, apesar de menor |
| CodeLlama | 34B par√¢metros | Tarefas de programa√ß√£o | Supera outros modelos open-source em benchmarks de codifica√ß√£o como HumanEval e MBPP |
| StarCoder | - | Gera√ß√£o de c√≥digo em diversas linguagens | Modelo do projeto BigCode, similar ao CodeLlama |
| Mistral | 7B par√¢metros | Tarefas gerais de linguagem e codifica√ß√£o | T√©cnicas como Grouped Query Attention e Sliding Window Attention para efici√™ncia; bom desempenho em tarefas de programa√ß√£o |
| Claude | - | Tarefas gerais de linguagem | Modelo propriet√°rio da Anthropic, n√£o especializado em codifica√ß√£o |

Observa√ß√µes adicionais:

- Vers√µes fine-tuned do CodeLlama, como o Phind-CodeLlama, alcan√ßam resultados ainda melhores em benchmarks de codifica√ß√£o.
- Apesar de menor, o Mistral tem um desempenho compar√°vel ao CodeLlama 7B em tarefas de programa√ß√£o, mantendo bom desempenho em outras tarefas de linguagem.

### Refer√™ncias

Gerado por [Perplexity IA](https://www.perplexity.ai/)

- [Processamento de Linguagem Natural - 15¬† Modelos de Linguagem](https://brasileiraspln.com/livro-pln/1a-edicao/parte7/cap15/cap15.html)
- [As diferen√ßas nos modelos de linguagem](https://www.meioemensagem.com.br/proxxima/diferencas-modelos-de-linguagem)
- [Modelo de linguagem ‚Äì Wikip√©dia, a enciclop√©dia livre](https://pt.wikipedia.org/wiki/Modelo_de_linguagem)
- [Modelos de linguagem de grande escala ‚Äì Wikip√©dia, a enciclop√©dia livre](https://pt.wikipedia.org/wiki/Modelos_de_linguagem_de_grande_escala)
- [O Que S√£o Large Language Models (LLMs)? - Data Science Academy](https://blog.dsacademy.com.br/o-que-sao-large-language-models-llms/)
- [Ollama library](https://ollama.com/library)
- [üè° Home | Open WebUI](https://docs.openwebui.com/)
- [Streaming language models ‚Äì¬†Replicate](https://replicate.com/collections/streaming-language-models)
- [Top Open-Source LLMs for Coding](https://www.e2enetworks.com/blog/top-8-open-source-llms-for-coding)
- [Philipp Schmid no LinkedIn: Large-scale Near-deduplication Behind BigCode](https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_large-scale-near-deduplication-behind-bigcode-activity-7064989685030215681-cjbo)
- [GitHub - continuedev/what-llm-to-use: üëÄ What LLM to use?](https://github.com/continuedev/what-llm-to-use)
- [EvalPlus Leaderboard](https://evalplus.github.io/leaderboard.html)
